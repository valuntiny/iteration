---
title: "Writing functions"
output: github_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

library(tidyverse)
library(rvest)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```


writing a z-score function

```{r}
z_scores = function(x) {
  return (mean(x) / sd(x))
}
```

now check if it works

```{r, error = TRUE}
# ignore the error, and keep going

y = runif(100)

z_scores(y)

z_scores(3)
z_scores("my name is jeff")
z_scores(iris)
z_scores(sample(c(TRUE, FALSE), 25, replace = TRUE))
```

now put in some checks on inputs

```{r}
z_scores = function(x) {
  
  if (!is.numeric(x)) {
    stop("Argument x should be numeric")
  } else if (length(x) == 1) {
    stop("Z scores cannot be computed for length 1 vectors")
  }
  
  z = mean(x) / sd(x)
  
  z
}
```

multiple input

```{r}
sim_regression = function(n, beta0 = 2, beta1 = 3) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 1, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, 1)
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta0_hat = coef(ls_fit)[1],
    beta1_hat = coef(ls_fit)[2]
  )
}
```

check

```{r}
sim_regression(1000) # it's better to put the parameter in "x = , y = , z = " format
```

## 

```{r}
read_page_reviews <- function(url) {
  
  h = read_html(url)
  
  review_titles = h %>%
    html_nodes("#cm_cr-review_list .review-title") %>%
    html_text()
  
  review_stars = h %>%
    html_nodes("#cm_cr-review_list .review-rating") %>%
    html_text() %>%
    str_extract("\\d") %>%
    as.numeric()
  
  review_text = h %>%
    html_nodes(".review-data:nth-child(4)") %>%
    html_text()
  
  tibble(
    title = review_titles,
    stars = review_stars,
    text = review_text
  )
}
```

```{r}
url_base = "https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber="
urls = str_c(url_base, 1:5)

dynamite_reviews = bind_rows(
  read_page_reviews(urls[1]),
  read_page_reviews(urls[2]),
  read_page_reviews(urls[3]),
  read_page_reviews(urls[4]),
  read_page_reviews(urls[5])
)
```

## for loops

```{r}
l = list(vec_numeric = 5:8,
         mat         = matrix(1:8, 2, 4),
         vec_logical = c(TRUE, FALSE),
         summary     = summary(rnorm(1000))
         )

df = data_frame(
  a = rnorm(20, 3, 1),
  b = rnorm(20, 0, 5),
  c = rnorm(20, 10, .2),
  d = rnorm(20, -3, 1)
)

mean_and_sd = function(x) {
  if (!is.numeric(x)) {
    stop("Argument x should be numeric")
  } else if (length(x) == 1) {
    stop("Cannot be computed for length 1 vectors")
  }
  
  mean_x = mean(x)
  sd_x = sd(x)

  tibble(
    mean = mean_x, 
    sd = sd_x
  )
}
```

write a for loop:

```{r}
output = vector("list", length = 4)

for (i in 1:4) {
  output[[i]] = mean_and_sd(df[[i]])
}
```

## replace for loop with map

```{r}
output = map(df, mean_and_sd)

# or use tidy to apply on some specific column
df %>% 
  select(a,b) %>% 
  map(mean_and_sd)

# default of output format of map is list, now we use some other format output
output = map_df(df, mean_and_sd)
```

## nest list columns

```{r}
library(rnoaa)

weather = 
  meteo_pull_monitors(c("USW00094728", "USC00519397", "USS0023B17S"),
                      var = c("PRCP", "TMIN", "TMAX"), 
                      date_min = "2016-01-01",
                      date_max = "2016-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY", 
                      USC00519397 = "Waikiki_HA",
                      USS0023B17S = "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

weather_nest = 
  weather %>% 
  nest(date:tmin) # you could use group_by first to specify the column you wanna nest

weather_nest %>% pull(name)
weather_nest %>% pull(data)
```

unnest

```{r}
unnest(weather_nest)
```

## linear model

```{r}
# linear model for tmax and tmin column
lm(tmax ~ tmin, data = weather_nest$data[[1]])
lm(tmax ~ tmin, data = weather_nest$data[[2]])
lm(tmax ~ tmin, data = weather_nest$data[[3]])

# or use map function
weather_lm = function(df) {
  lm(tmax ~ tmin, data = df)
}

map(weather_nest$data, weather_lm)
```

Then add the output as new column to the origin dataset

```{r}
weather_nest %>% 
  mutate(lm_result = map(data, weather_lm))
```

## SLR

```{r}
set.seed(1)

sim_regression = function(n, beta0 = 2, beta1 = 3) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 1, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, 1)
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta0_hat = coef(ls_fit)[1],
    beta1_hat = coef(ls_fit)[2]
  )
}

output = vector("list", 100)

for (i in 1:100) {
  output[[i]] = sim_regression(30) # sample size = 30
}

sim_results = bind_rows(output)
```

using rerun instead

```{r}
sim_results = 
  rerun(100, sim_regression(30, 2, 3)) %>% 
  bind_rows()

sim_results %>% 
  ggplot(aes(x = beta0_hat, y = beta1_hat)) + 
  geom_point()
```

gathering result

```{r}
sim_results %>% 
  gather(key = parameter, value = estimate, beta0_hat:beta1_hat) %>% 
  group_by(parameter) %>% 
  summarize(emp_mean = mean(estimate),
            emp_var = var(estimate)) %>% 
  knitr::kable(digits = 3)
```

## n SLRs (for loop)

```{r}
n_list = list("n_30"  = 30, 
              "n_60"  = 60, 
              "n_120" = 120, 
              "n_240" = 240)
output = vector("list", length = 4)

for (i in 1:4) {
  output[[i]] = rerun(100, sim_regression(n_list[[i]])) %>% 
    bind_rows
}
```

or, we could use function and tidying to implement it

```{r}
simulate_n_regressions = function(n_runs = 100, n, beta0 = 2, beta1 = 3) {
  
  rerun(n_runs, sim_regression(n, beta0, beta1)) %>% 
    bind_rows()
  
}

sim_results = 
  tibble(sample_size = c(30, 60, 120, 240)) %>% 
  mutate(estimate_dfs = map(.x = sample_size, ~simulate_n_regressions(n = .x))) %>% 
  unnest
```

or we run it 1000 times and plot

```{r}
sim_results = 
  tibble(sample_size = c(30, 60, 120, 240)) %>% 
  mutate(estimate_dfs = map(.x = sample_size, ~simulate_n_regressions(n_runs = 1000, n = .x))) %>% 
  unnest

sim_results %>% 
  mutate(
    sample_size = str_c("n = ", sample_size),
    sample_size = fct_inorder(sample_size)) %>% 
  ggplot(aes(x = sample_size, y = beta1_hat, fill = sample_size)) + 
  geom_violin()
```

Then, look at the bivariate distribution of intercept and slope estimates across sample sizes.

```{r}
sim_results %>% 
  mutate(
    sample_size = str_c("n = ", sample_size),
    sample_size = fct_inorder(sample_size)) %>% 
  ggplot(aes(x = beta0_hat, y = beta1_hat)) + 
  geom_point(alpha = .2) + 
  facet_grid(~sample_size)
```

Lastly look at the empirical mean and variance of these estimates.

```{r}
sim_results %>% 
  gather(key = parameter, value = estimate, beta0_hat:beta1_hat) %>% 
  group_by(parameter, sample_size) %>% 
  summarize(emp_mean = mean(estimate),
            emp_var = var(estimate)) %>% 
  knitr::kable(digits = 3)
```

## publication bias


using different beta1 value

```{r}
sim_regression = function(n_samp = 30, beta0 = 2, beta1 = 3) {
  
  sim_data = tibble(
    x = rnorm(n_samp),
    y = beta0 + beta1 * x + rnorm(n_samp, 0, sqrt(50))
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  broom::tidy(ls_fit) # cleanly format the results of lm
  
}

sim_results = 
  tibble(beta1_true = 0:6) %>% 
  mutate(
    estimate_dfs = map(.x = beta1_true, ~simulate_n_regressions(n_runs = 1000, n = 30, beta1 = .x))
  )  
```

plot

```{r}
sim_results = 
  sim_results %>% 
  unnest() %>% 
  filter(term == "x") %>% 
  select(beta1_true, estimate, p.value) %>% 
  mutate(significant = as.numeric(p.value < 0.05))

sim_results %>% 
  group_by(beta1_true) %>% 
  summarise(proportion = mean(significant)) %>% 
  ggplot(aes(x = beta1_true, y = proportion)) +
  geom_line()
```

average of β̂ 1 on the y axis and the true value of β1 on the x axis (in red), along with the average of β̂ 1 in cases for which the null is reject (in blue)

```{r}
results_summary = 
  sim_results %>% 
  group_by(beta1_true) %>%
  nest() %>% 
  mutate(
    all = map_dbl(.x = data, ~ .x %>% pull(estimate) %>% mean),
    signif = map_dbl(.x = data, ~ .x %>% filter(significant == 1) %>% pull(estimate) %>% mean)
  ) %>% 
  select(-data) %>% 
  gather(key = results, value = average, all:signif) 

results_summary %>% 
  ggplot(aes(x = beta1_true, y = average, color = results)) + 
  geom_point() +
  geom_path()
```

